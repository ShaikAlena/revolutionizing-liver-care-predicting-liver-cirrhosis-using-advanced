{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b587c4ba",
   "metadata": {},
   "source": [
    "# Liver Cirrhosis Prediction Using Machine Learning\n",
    "This notebook trains a model to predict liver cirrhosis using clinical data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dd36e92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Upload dataset\n",
    "from google.colab import files\n",
    "uploaded = files.upload()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a9535de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Import required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "import pickle\n",
    "import io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "474e8038",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Load CSV file\n",
    "filename = list(uploaded.keys())[0]\n",
    "data = pd.read_csv(io.BytesIO(uploaded[filename]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e9d506e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Check column names\n",
    "print(\"Columns in dataset:\", data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d63bbe49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 5: Rename target column\n",
    "data.rename(columns={'liver_disease': 'Class'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c352def",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 6: Handle missing values\n",
    "data.fillna(data.mean(), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f31a867",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 7: One-hot encode gender if present\n",
    "if 'Gender' in data.columns:\n",
    "    data['Gender'] = data['Gender'].map({'Male': 1, 'Female': 0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a768e9d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 8: Split into features and target\n",
    "X = data.drop('Class', axis=1)\n",
    "y = data['Class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e7c629b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 9: Scale input data\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5c79ec9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 10: Train/Test Split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a3b0a21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 11: Train Random Forest model\n",
    "model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7c2ebb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 12: Evaluate model\n",
    "y_pred = model.predict(X_test)\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34144300",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 13: Save model and scaler\n",
    "with open('rf_acc_68.pkl', 'wb') as f:\n",
    "    pickle.dump(model, f)\n",
    "\n",
    "with open('normalizer.pkl', 'wb') as f:\n",
    "    pickle.dump(scaler, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fa79e92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 14: Download saved files\n",
    "files.download('rf_acc_68.pkl')\n",
    "files.download('normalizer.pkl')"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}